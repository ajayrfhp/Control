{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "import wget\n",
    "import os\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from fpl import FPL\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from player import Player\n",
    "from team import Team\n",
    "from data_processor import get_fpl, get_players, get_teams, get_training_datasets, get_all_player_features\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl = await get_fpl()\n",
    "team_feature_names = [\"npxGA\"]\n",
    "teams = get_teams(team_feature_names=team_feature_names, visualize=False)\n",
    "player_feature_names = [\"total_points\", \"ict_index\", \"clean_sheets\", \"saves\", \"assists\"]\n",
    "players = await get_players(player_feature_names, team_feature_names, visualize=False, num_players=590)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(22522, 6, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "def get_timeseries_dataset(players, input_features = 5, context_window=6, epsilon=1e-6):\n",
    "    '''\n",
    "        Args\n",
    "            players - List of players \n",
    "            input_features - Number of feature dimensions; len(player_feature_names)\n",
    "            context_window - length of prediction context window\n",
    "        Returns\n",
    "            Time series dataset that is a numpy array of shape (N, context_window, input_features)\n",
    "    '''\n",
    "    timeseries_dataset = []\n",
    "    for player in players:\n",
    "        player_points = player.player_features.T\n",
    "        for i in range(len(player_points) - context_window):\n",
    "            timeseries_dataset.append(player_points[i:i+context_window,:])\n",
    "    random.shuffle(timeseries_dataset)\n",
    "    timeseries_dataset = np.array(timeseries_dataset).astype(float) # (N, context_window, input_features)\n",
    "    return timeseries_dataset\n",
    "\n",
    "\n",
    "timeseries_dataset = get_timeseries_dataset(players)\n",
    "timeseries_dataset.shape # (N, context_window, input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]\n[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(22522, 6, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "def normalize(x, epislon=1e-6):\n",
    "    '''\n",
    "    Args\n",
    "        x - numpy array of shape (N, L, D)\n",
    "    Returns\n",
    "        normalized_x - normalized numpy array of shape (N, L, D). Normalized along dimension D\n",
    "    '''\n",
    "    means = np.mean(np.mean(x, axis=0), axis=0)\n",
    "    stds = np.std(np.std(x, axis=0), axis=0)\n",
    "    normalized_x = (x - means) / (stds+epislon)\n",
    "    return normalized_x\n",
    "\n",
    "print(timeseries_dataset[10])\n",
    "print(normalize(timeseries_dataset[10]))\n",
    "normalized_timeseries_dataset = normalize(timeseries_dataset)\n",
    "normalized_timeseries_dataset.shape\n"
   ]
  },
  {
   "source": [
    "# Dynamic data augmentation\n",
    "- Input window is x [0:7]. 2 elements are set to 0 at random\n",
    "- Target is sampled form x[7:9]\n",
    "- Why - I want an nearly infinite dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[4.],\n         [6.],\n         [8.]]], dtype=torch.float64)\ntensor([6.], dtype=torch.float64)\ntensor([8.], dtype=torch.float64)\ntensor([[2.5555]], dtype=torch.float64, grad_fn=<AddmmBackward>)\ntensor([[1.6050]], dtype=torch.float64, grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "class AvgModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def forward(self, x):\n",
    "        # shape of x is (Batch_size, L * D)\n",
    "        return x.mean(dim=-1)\n",
    "\n",
    "class PrevModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def forward(self, x):\n",
    "        # shape of x is (Batch_size, L, D)\n",
    "        return x[:,-1, 0]\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_window):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.input_window = input_window\n",
    "        self.fc1 = nn.Linear(input_window, 1).double()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # shape of x is (Batch_size, L * D)\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class NonLinearModel(nn.Module):\n",
    "    def __init__(self, input_window):\n",
    "        super(NonLinearModel, self).__init__()\n",
    "        self.model = nn.Sequential(*[nn.Linear(input_window, 100).double(),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(100, 100).double(),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(100, 1).double()])\n",
    "    def forward(self, x):\n",
    "        # shape of x is (Batch_size, L * D)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "input_tensor = torch.tensor([4, 6, 8]).double().reshape((1, 3, 1))\n",
    "print(input_tensor)\n",
    "\n",
    "avg_model = AvgModel()\n",
    "print(avg_model.forward(input_tensor.reshape((-1, 3))))\n",
    "\n",
    "prev_model = PrevModel()\n",
    "print(prev_model.forward(input_tensor))\n",
    "\n",
    "linear_model = LinearModel(input_window=3)\n",
    "print(linear_model.forward((input_tensor.reshape((-1, 3)))))\n",
    "\n",
    "non_linear_model = NonLinearModel(input_window=3)\n",
    "print(non_linear_model.forward((input_tensor.reshape((-1, 3)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = int(0.8 * len(timeseries_dataset))\n",
    "train_dataset, test_dataset = timeseries_dataset[:train_indices], timeseries_dataset[train_indices:]\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(train_dataset)), batch_size=1)\n",
    "test_loader = DataLoader(TensorDataset(torch.tensor(test_dataset)), batch_size=1)\n",
    "input_window_length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, epochs=30, input_context_window=6, len_features=5, input_window_length=4):\n",
    "    optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "    for epoch in range(epochs): \n",
    "        for [x] in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_vector = x[:,:input_window_length]\n",
    "            if isinstance(model, LinearModel) or isinstance(model, NonLinearModel) or isinstance(model, AvgModel):\n",
    "                input_vector = input_vector.reshape((-1, input_window_length * len_features))\n",
    "            outputs_choice = np.random.choice([4])\n",
    "            outputs = x[:,outputs_choice,0]\n",
    "            predictions = model.forward(input_vector)\n",
    "            #print(x.shape, input_vector.shape, outputs.shape, predictions.shape)\n",
    "            residual = (predictions - outputs)\n",
    "            loss = (residual * residual).sum() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def eval(model, test_loader, test_choices, input_context_window=6, len_features=5, input_window_length=4):\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "    for [ [x], outputs_choice] in zip(test_loader, test_choices):\n",
    "        input_vector = x[:,:input_window_length]\n",
    "        if isinstance(model, LinearModel) or isinstance(model, NonLinearModel) or isinstance(model, AvgModel):\n",
    "            input_vector = input_vector.reshape((-1, input_window_length * len_features))\n",
    "        outputs = x[:,outputs_choice, 0]\n",
    "        predictions = model.forward(input_vector)\n",
    "        sum_loss += (predictions - outputs).abs().mean().item()\n",
    "        count_loss += 1\n",
    "        #break\n",
    "    return sum_loss / count_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.3317180910099897\n1.588679245283019\n1.5092664724938767\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'asd'"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "avg_losses = []\n",
    "prev_losses = []\n",
    "linear_losses = []\n",
    "non_linear_losses = []\n",
    "for seed in [35]:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    test_choices = [np.random.choice([4]) for _ in test_loader]\n",
    "\n",
    "    avg_model = AvgModel()\n",
    "    prev_model = PrevModel()\n",
    "    linear_model = LinearModel(input_window_length * len(player_feature_names))\n",
    "    non_linear_model = NonLinearModel(input_window_length * len(player_feature_names))\n",
    "    \n",
    "    fit(linear_model, train_loader)\n",
    "    #fit(non_linear_model, train_loader)\n",
    "    avg_losses.append(eval(avg_model, test_loader, test_choices))\n",
    "    prev_losses.append(eval(prev_model, test_loader, test_choices))\n",
    "    linear_losses.append(eval(linear_model, test_loader, test_choices))\n",
    "    #non_linear_losses.append(eval(non_linear_model, test_loader, test_choices))\n",
    "print(sum(avg_losses) / len(avg_losses))\n",
    "print(sum(prev_losses) / len(prev_losses))\n",
    "print(sum(linear_losses) / len(linear_losses))\n",
    "'asd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}