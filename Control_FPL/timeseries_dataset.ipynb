{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "import wget\n",
    "import os\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from fpl import FPL\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from player import Player\n",
    "from team import Team\n",
    "from data_processor import get_fpl, get_players, get_teams, get_training_datasets, get_all_player_features\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl = await get_fpl()\n",
    "team_feature_names = [\"npxGA\"]\n",
    "teams = get_teams(team_feature_names=team_feature_names, visualize=False)\n",
    "player_feature_names = [\"total_points\", \"ict_index\", \"clean_sheets\", \"saves\", \"assists\", \"yellow_cards\"]\n",
    "players = await get_players(player_feature_names, team_feature_names, visualize=False, num_players=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([25415, 6, 3]), torch.Size([25415]))"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "def get_timeseries_dataset(players, input_window=3, input_features=len(player_feature_names)):\n",
    "    '''\n",
    "        Args\n",
    "            players - List of players \n",
    "            input_window - input window \n",
    "            input_features - number of input features\n",
    "        Returns\n",
    "            Time series dataset that is a numpy array of shape (N, input_window, input_features)\n",
    "    '''\n",
    "    X, Y = [], []\n",
    "    for player in players:\n",
    "        player_points = player.player_features # (input_features, timesteps)\n",
    "        for i in range(player_points.shape[1] - input_window):\n",
    "            x = player_points[:,i:i+input_window]\n",
    "            y = player_points[0, i+input_window]\n",
    "            X.append(x), Y.append(y)\n",
    "    X, Y = np.array(X).astype(float), np.array(Y).astype(float)\n",
    "    X, Y = torch.tensor(X), torch.tensor(Y)\n",
    "    return X, Y\n",
    " \n",
    "\n",
    "X, Y =  get_timeseries_dataset(players)\n",
    "X.shape, Y.shape # (N, input_features, context_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([25415, 6, 3]), torch.Size([25415]))"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "def normalize(x, epislon=1e-6, is_scalar=False):\n",
    "    '''\n",
    "    Args\n",
    "        x - numpy array of shape (N, L, D)\n",
    "    Returns\n",
    "        normalized_x - normalized numpy array of shape (N, L, D). Normalized along dimension D\n",
    "    '''\n",
    "    if is_scalar:\n",
    "        return (x - x.mean()) / (x.std())\n",
    "    means = torch.mean(x, axis=[0, 1])\n",
    "    stds = torch.std(x, axis=[0, 1])\n",
    "    return (x - means) / stds\n",
    "\n",
    "X = X.permute((0, 2, 1))\n",
    "X, Y = normalize(X), normalize(Y, is_scalar=True)\n",
    "X = X.permute((0, 2, 1))\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "source": [
    "# Dynamic data augmentation\n",
    "- Input window is x [0:7]. 2 elements are set to 0 at random\n",
    "- Target is sampled form x[7:9]\n",
    "- Why - I want an nearly infinite dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[4.],\n         [6.],\n         [8.]]], dtype=torch.float64)\ntensor([6.], dtype=torch.float64)\ntensor([8.], dtype=torch.float64)\ntensor([7.9072], dtype=torch.float64, grad_fn=<ViewBackward>)\ntensor([[0.8767]], dtype=torch.float64, grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "class AvgModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def forward(self, x):\n",
    "        # shape of x is (Batch_size, L, D)\n",
    "        return x[:,:, 0].mean(dim=-1)\n",
    "\n",
    "class PrevModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def forward(self, x):\n",
    "        # shape of x is (Batch_size, L, D)\n",
    "        return x[:,-1, 0]\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_window):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.input_window = input_window\n",
    "        self.fc1 = nn.Linear(input_window, 1).double()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # shape of x is (Batch_size, L * D)\n",
    "        return self.fc1(x).view((-1, ))\n",
    "\n",
    "\n",
    "class NonLinearModel(nn.Module):\n",
    "    def __init__(self, input_window):\n",
    "        super(NonLinearModel, self).__init__()\n",
    "        self.model = nn.Sequential(*[nn.Linear(input_window, 100).double(),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(100, 100).double(),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(100, 1).double()])\n",
    "    def forward(self, x):\n",
    "        # shape of x is (Batch_size, L * D)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "input_tensor = torch.tensor([4, 6, 8]).double().reshape((1, 3, 1))\n",
    "print(input_tensor)\n",
    "\n",
    "avg_model = AvgModel()\n",
    "print(avg_model.forward(input_tensor))\n",
    "\n",
    "prev_model = PrevModel()\n",
    "print(prev_model.forward(input_tensor))\n",
    "\n",
    "linear_model = LinearModel(input_window=3)\n",
    "print(linear_model.forward((input_tensor.reshape((-1, 3)))))\n",
    "\n",
    "non_linear_model = NonLinearModel(input_window=3)\n",
    "print(non_linear_model.forward((input_tensor.reshape((-1, 3)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fac066aa070>"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "\n",
    "train_indices = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_indices], X[train_indices:]\n",
    "Y_train, Y_test = Y[:train_indices], Y[train_indices:]\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, Y_train), batch_size=25)\n",
    "test_loader = DataLoader(TensorDataset(X_test, Y_test), batch_size=25)\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, epochs=10, input_window=3, len_features=len(player_feature_names)):\n",
    "    optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "    for epoch in range(epochs): \n",
    "        for (inputs, outputs) in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            if isinstance(model, LinearModel) or isinstance(model, NonLinearModel):\n",
    "                inputs = inputs.reshape((-1, input_window * len_features))\n",
    "            predictions = model.forward(inputs)\n",
    "            residual = (predictions - outputs)\n",
    "            loss = (residual * residual).sum() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def eval(model, test_loader,input_window = 3, len_features=len(player_feature_names)):\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "    \n",
    "    for (inputs, outputs)  in test_loader:\n",
    "        if isinstance(model, LinearModel) or isinstance(model, NonLinearModel):\n",
    "            inputs = inputs.reshape((-1, input_window * len_features))\n",
    "        predictions = model.forward(inputs)\n",
    "        sum_loss += (predictions - outputs).abs().mean().item()\n",
    "        count_loss += 1\n",
    "\n",
    "    return sum_loss / count_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.533986998801052\n0.7013903232227673\n0.48374184837916046\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'asd'"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "input_window = 3\n",
    "avg_losses = []\n",
    "prev_losses = []\n",
    "linear_losses = []\n",
    "non_linear_losses = []\n",
    "for seed in [5, 10, 25, 35]:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    avg_model = AvgModel()\n",
    "    prev_model = PrevModel()\n",
    "    linear_model = LinearModel(input_window * len(player_feature_names))\n",
    "    fit(linear_model, train_loader)\n",
    "    avg_losses.append(eval(avg_model, test_loader))\n",
    "    prev_losses.append(eval(prev_model, test_loader))\n",
    "    linear_losses.append(eval(linear_model, test_loader))\n",
    "print(sum(avg_losses) / len(avg_losses))\n",
    "print(sum(prev_losses) / len(prev_losses))\n",
    "print(sum(linear_losses) / len(linear_losses))\n",
    "'asd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}