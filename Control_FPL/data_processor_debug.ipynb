{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('control': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d1683d455970a83140547a7a38696e216f7e48aaa3baf122702e1f94335bc7e6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff7cf7f2630>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wget\n",
    "import os\n",
    "import aiohttp\n",
    "import asyncio\n",
    "np.random.seed(17)\n",
    "random.seed(17)\n",
    "torch.manual_seed(17)\n",
    "from fpl import FPL\n",
    "from player import Player\n",
    "from team import Team\n",
    "from data_processor import get_fpl, get_players, get_teams, get_training_datasets\n",
    "from models import PreviousScoreModel, PlayerAvgScoreModel, LinearModel, HierarchialLinearModel, NonLinearModel\n",
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Ezgjan Alioski'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "fpl = await get_fpl()\n",
    "opponent_feature_names = [\"npxG\",\"npxGA\"]\n",
    "player_feature_names = [\"total_points\", \"ict_index\", \"clean_sheets\", \"saves\", \"assists\"]\n",
    "teams = get_teams(team_feature_names=opponent_feature_names, visualize=False)\n",
    "players = await get_players(player_feature_names, opponent_feature_names, visualize=False, num_players=580)\n",
    "players[200].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heirarchical_datasets(player_features_array, opponent_features_array, total_points_array, points_this_season_array, batch_size):\n",
    "    '''\n",
    "        Function does the following\n",
    "            - Normalize feature arrays and store normalizers\n",
    "            - Gets train, test loaders, normalizers and returns them\n",
    "        Args\n",
    "        Returns\n",
    "            (train_loader, test_loader, normalizers)\n",
    "    '''\n",
    "    indices = np.random.permutation(range(0, len(player_features_array)))\n",
    "    indices = range(0, len(player_features_array))\n",
    "    train_length = int(0.8 * len(indices))\n",
    "\n",
    "    # Normalize player feature array\n",
    "    player_features_array, player_features_means, player_features_stds = normalize(player_features_array) # (N, D, T)\n",
    "    opponent_features_array, opponent_features_means, opponent_features_stds = normalize(opponent_features_array) # (N, D, T)\n",
    "    total_points_array, total_points_means, total_points_stds = normalize(total_points_array, is_scalar=True) #(N, 1)\n",
    "    points_this_season_array, points_this_season_means, points_this_season_stds = normalize(points_this_season_array, is_scalar=True) #(N, 1)    \n",
    "\n",
    "    train_player_features_array, test_player_features_array = player_features_array[indices[:train_length]], player_features_array[indices[train_length:]]\n",
    "    train_opponent_features_array, test_opponent_features_array = opponent_features_array[indices[:train_length]], opponent_features_array[indices[train_length:]]\n",
    "    train_total_points_array, test_total_points_array = total_points_array[indices[:train_length]], total_points_array[indices[train_length:]]\n",
    "    \n",
    "    train_points_this_season_array, test_points_this_season_array = points_this_season_array[indices[:train_length]], points_this_season_array[indices[train_length:]]\n",
    "\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(train_player_features_array, train_opponent_features_array, train_points_this_season_array, train_total_points_array), batch_size=batch_size)\n",
    "    test_loader = DataLoader(TensorDataset(test_player_features_array, test_opponent_features_array, test_points_this_season_array, test_total_points_array), batch_size=batch_size)\n",
    "    return train_loader, test_loader, (player_features_means, player_features_stds, opponent_features_means, opponent_features_stds, points_this_season_means , points_this_season_stds, total_points_means, total_points_stds)\n",
    "\n",
    "def get_training_datasets(players, teams, window=4, batch_size=50, visualize=False, autoregressive=False):\n",
    "    player_features_array = []\n",
    "    opponent_features_array = []\n",
    "    total_points_array = []\n",
    "    points_this_season_array = []\n",
    "    for player in players:\n",
    "        player_features = player.player_features # ( D * L matrix)\n",
    "        opponents = player.opponents.reshape((-1, 1)) # (1 * L matrix)\n",
    "        \n",
    "        player_feature_chunks = []\n",
    "        opponent_chunks = []\n",
    "        total_points = []\n",
    "        points_this_season = []\n",
    "\n",
    "        # Break (D * L) matrix into (L - W + 1) D * W matrices\n",
    "        for i in range(player_features.shape[1] - window - 1):\n",
    "            player_feature_chunk = player_features[:,i:i+window]\n",
    "            opponent_chunk = (i+window, opponents[i+window])\n",
    "            total_point = player_features[0, i+window]\n",
    "            point_this_season = player_features[0, :i+window].sum()\n",
    "            \n",
    "            player_feature_chunks.append(player_feature_chunk)\n",
    "            opponent_chunks.append(opponent_chunk) \n",
    "            total_points.append(total_point)\n",
    "            points_this_season.append(point_this_season)\n",
    "\n",
    "        if len(player_feature_chunks) == 0:\n",
    "            continue\n",
    "        opponent_feature_chunks = []\n",
    "        for i, opponent in opponent_chunks:\n",
    "            for team in teams:\n",
    "                if team.name == opponent:\n",
    "                    opponent_feature = team.team_features[:,i-window:i]\n",
    "                    if opponent_feature.shape[1] != window:\n",
    "                        opponent_feature = np.zeros((opponent_feature.shape[0], window))\n",
    "                    opponent_feature_chunks.append(opponent_feature)\n",
    "        \n",
    "        opponent_feature_chunks = np.array(opponent_feature_chunks)\n",
    "        player_features_array.extend(player_feature_chunks)\n",
    "        opponent_features_array.extend(opponent_feature_chunks)\n",
    "        total_points_array.extend(total_points)\n",
    "        points_this_season_array.extend(points_this_season)\n",
    "    \n",
    "    if autoregressive:\n",
    "        return get_autoregressive_datasets(player_features_array, opponent_features_array, total_points_array, points_this_season_array, batch_size)\n",
    "    return get_heirarchical_datasets(player_features_array, opponent_features_array, total_points_array, points_this_season_array, batch_size)\n",
    "\n",
    "def normalize(input_array, is_scalar = False):\n",
    "    if not is_scalar:\n",
    "        input_array = torch.tensor(np.array(input_array).astype(float)).double() # (N, D, W)\n",
    "        input_means = torch.mean(input_array, dim=(0, 2)) # Means is d dimensional\n",
    "        input_stds = torch.std(input_array, dim=(0, 2))\n",
    "        input_array = input_array.permute(0, 2, 1) # Convert to (N, W, D) to do the normalization\n",
    "        # input_array = (input_array - input_means) / (input_stds)\n",
    "        input_array = input_array.permute(0, 2, 1) # Reset to (N, D, W)\n",
    "        return input_array, input_means, input_stds\n",
    "    else:\n",
    "        input_array = torch.tensor(np.array(input_array).astype(float).reshape((-1, 1))).double()\n",
    "        input_means = torch.mean(input_array)\n",
    "        input_stds = torch.std(input_array)\n",
    "        # input_array = (input_array - input_means) / input_stds\n",
    "        return input_array, input_means, input_stds\n",
    "\n",
    "\n",
    "train_loader, test_loader, _ = get_training_datasets(players, teams)\n",
    "train_loader, test_loader\n",
    "x, _,_, y = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[5.0000, 2.0000, 1.0000, 0.0000],\n",
       "         [6.7000, 4.8000, 1.9000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 0.0000]], dtype=torch.float64),\n",
       " tensor([2.], dtype=torch.float64))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "x[14], y[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}